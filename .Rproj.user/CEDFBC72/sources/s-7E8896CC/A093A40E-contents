---
title: "Modelo Churn"
author: "Eduardo Vásquez Nolasco"
date: "25/07/2020"
output: html_document
---

<style>
body {
text-align: justify}
</style>

# Modelo Churn

La adquisición de un cliente en la empresa presenta costos asociados a este. Además, el costo de adquirir un nuevo cliente suele ser más elevado que en el que incurre la empresa en retenerlo. Por ende, es relevante lograr una fidelización de estos para asegurar la existencia del negocio en el tiempo. En ese sentido, se utilizan los modelos churn con el objetivo de conocer la propensión de que el cliente abandone la empresa y se transforme en un ex-usuario. 
  

###  Explorar la data

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(patchwork)
library(ggplot2)
library(recipes)
library(tidyr)
library(tidymodels)
library(themis)
library(corrplot)
library(recipes)
library(modeldata)
library(cvms)
library(caret)
library(vip)
library(yardstick)
library(plotly)

data_churn <- read.csv("Data/data_churn.csv")

```

### Estructura de la data

Se observa estadística descriptiva, distribución de las variables y que existen valores perdidos en esta. 

* El 14.5% de los registros son ex-usuarios de la empresa. Se muestra que existe un problema de clase desequilibrada  en la variable churn.

* Se observa mayor consumo de minutos en la tarde y en la noche en comparación con la mañana.

* En promedio, las mayores facturaciones se registran en horarios de la tarde.

* Los usuarios tienden a llamar 1.56 veces al mes a los centros de atención. Además, se observa que la distribución tiene un sesgo positivo.

* A las variables Total.intl.calls y Total.intl.charge se le remueven observaciones y se crean las nuevas variables International_calls e International_charges con el objetivo de probar la efectividad de técnicas de imputación de datos faltantes.

* Vemos que la variable International_calls tiene 14 valores perdidos.  

* La variable International_charges tiene 10 valores perdidos.

* Sin embargo, 2 de estos valores perdidos se encuentran en el mismo usuario.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# Observar la estructura de la data 
skimr::skim(data_churn)

# Tenemos 2 variables con valores perdidos.
data_churn %>% 
  select(International_calls, International_charges) %>% 
  naniar::gg_miss_upset()

```

### Imputar valores perdidos

* Se observa la distribución de la data:

  + International calls presenta una distribución con asimetría positiva. En ese tenor, se procede a usar un algoritmo de k-nearest neighbors.

  + Por el contrario, International charges tiende a converger a una distribución normal, por ende, se opta por imputar los valores con la media.  

```{r, echo = FALSE, message = FALSE, warning = FALSE}


density_int_call <- data_churn %>% 
  ggplot(aes(x = International_calls)) + 
  geom_density(color = "midnightblue", fill= "midnightblue",
               alpha = .5) +
  theme_minimal() +
  labs(
    y = "Densidad",
    x = "International calls" 
     )
  

density_int_charge <- data_churn %>% 
  ggplot(aes(x = International_charges)) + 
   geom_density(color = "darkred", fill = "darkred", 
                alpha = .5) +
  theme_minimal() +
  labs(
    y = "Densidad",
    x = "International charges" 
     )

density_int_call + density_int_charge 



```



* La media de los datos originales de las llamadas internacionales era  4.479, en el caso de los datos imputados resulta de 4.475. Respecto a las facturaciones de estas llamadas, la media de los datos originales era de 2.765, mientras que la imputada es de 2.764. En ese sentido, los datos imputados son cercanos a los originales.


```{r, echo = FALSE, message = FALSE, warning = FALSE}


imputar_datos <- recipe(~ International_calls + International_charges, data = data_churn) %>% 
                 step_meanimpute(International_charges) %>% 
                 step_knnimpute( all_predictors())

datos_imputados <- prep(imputar_datos) %>% 
                    juice()

 
# Verificar media de los datos imputados vs los datos reales
summary(datos_imputados)
summary(data_churn$Total.intl.calls)
summary(data_churn$Total.intl.charge)
 
# Verificar los valores imputados vs los valores reales
 
#data_churn %>% 
#  bind_cols(datos_imputados) %>% 
#  filter(is.na(International_calls) | is.na(International_charges)) %>% 
#  select(International_calls, International_charges,
#         Total.intl.calls, International_calls1,
#         Total.intl.charge, International_charges1)
```

### ¿Qué dice la data?

* Los que abandonan  la empresa son los que suelen facturar más al mes. Por ende, son clientes muy importantes que se deben retener.

* La mayor tasa de abandono de clientes se encuentra en California (CA) y Nueva Jersey (NJ).

* Los ex-usuarios son los que tendían a realizar mayor cantidad de llamadas a los centros de atención al cliente.

* Los ex-usuarios consumían mayor cantidad de minutos al mes que aquellos clientes que permanecen en la empresa. Además, preferían usar el servicio de telecomunicaciones en las mañanas y tardes.
  
 

```{r, echo = FALSE, message = FALSE, warning = FALSE }

# Ver la facturacion de los clientes que se nos van, que tan importantes son?

ggplotly(
data_churn %>% 
  mutate( facturacion = Total.day.charge + Total.night.charge +
                         Total.intl.charge + Total.eve.charge) %>% 
  ggplot(aes(x = Churn, y = facturacion)) +
  geom_boxplot(aes(fill = Churn)) +
  theme_minimal() +
  labs(
    y = "Facturación",
    x = "International charges" 
     )
) %>% 
  config(displayModeBar = F)


data_churn %>% 
  group_by(State) %>% 
  summarise(media_churn_estado = mean(Churn)) %>% 
  arrange(desc(media_churn_estado)) %>% 
  top_n(10) %>% 
  ggplot(aes(x = reorder(State, -media_churn_estado),
             y = media_churn_estado)) + 
  geom_col(fill = "midnightblue") + 
  labs(x = "Estado", 
       y = "Ratio de Churn") +
  theme_minimal()
```

```{r, echo = FALSE, message = FALSE, warning = FALSE, fig.height = 8, fig.width = 10}

# time they used
ggplotly(
data_churn %>% 
  bind_cols(datos_imputados) %>% 
  mutate(churn = Churn) %>% 
   select(-c(Account.length, Area.code, Total.intl.calls, Total.intl.charge, International_calls, International_charges, Total.day.charge, Total.eve.charge, Total.night.charge, Churn)) %>%
  pivot_longer(Number.vmail.messages:International_charges1, 
               names_to = "stat", values_to = "value") %>%
  ggplot(aes(churn, value, fill = churn, color = churn)) +
  geom_boxplot(alpha = 0.4) +
  facet_wrap(~stat, scales = "free_y", nrow = 2) +
  labs(y = NULL, color = NULL, fill = NULL) + theme_minimal() 
) %>%
  config(displayModeBar = F)

ggplotly(
data_churn %>% 
  transmute(day_consumption = Total.day.minutes + Total.day.calls,
         eve_consumption = Total.eve.minutes + Total.eve.calls,
         night_consumption = Total.night.minutes + Total.night.calls, 
         international_consumption = Total.intl.minutes + Total.intl.calls,
         minutes_consumption = Total.day.minutes + Total.eve.minutes + 
           Total.night.minutes,
         call_consumption = Total.day.calls + Total.eve.calls + 
          Total.night.calls,
         voice_vmail_messages = Number.vmail.messages,
         customer_serv_call  = Customer.service.calls,
         churn = Churn) %>% 
         pivot_longer(day_consumption:customer_serv_call, 
               names_to = "variable", values_to = "value") %>%
        ggplot(aes(x = value)) + geom_density(aes(fill = churn), alpha = 0.4 ) +
         facet_wrap(~ variable, scales="free") + scale_fill_brewer(palette = "Set1") + theme_minimal()  
) %>% 
  config(displayModeBar = F)
# data_churn %>% 
#  transmute(day_consumption = Total.day.minutes + Total.day.calls,
#         eve_consumption = Total.eve.minutes + Total.eve.calls,
#         night_consumption = Total.night.minutes + Total.night.calls, 
#         international_consumption = Total.intl.minutes + Total.intl.calls,
#         minutes_consumption = Total.day.minutes + Total.eve.minutes + 
#           Total.night.minutes,
#         call_consumption = Total.day.calls + Total.eve.calls + 
#          Total.night.calls,
#         voice_vmail_messages = Number.vmail.messages,
#         customer_serv_call  = Customer.service.calls,
#         churn = Churn) %>% 
#        gather("Variables","Quantity", -churn) %>% 
#        ggplot(aes(x = Quantity)) + geom_density(aes(fill = churn), alpha = 0.4 ) +
#         facet_wrap(~ Variables, scales="free") + scale_fill_brewer(palette = "Set1")
  
```


```{r, echo = FALSE, message = FALSE, warning = FALSE}
# corrplot::corrplot(cr2[1:15, 1:15], type = "upper")

 
 data_churn %>% 
  mutate(International.plan = ifelse(International.plan == "Yes", 1, 0),
          Voice.mail.plan = ifelse(Voice.mail.plan == "Yes", 1, 0)) %>% 
      select(-c(State, Account.length, Area.code, International_calls, International_charges, 
             Total.intl.calls, Total.intl.charge, International.plan, Voice.mail.plan)) %>% 
   cor() %>% 
   corrplot( type="upper")
  
```



* Se transforman las variables, se eliminan aquellas con alta correlación para evitar multicolinealidad y presentar un modelo más parsimonioso.

```{r, echo = FALSE, message = FALSE, warning = FALSE}


 data_churn <- data_churn %>% 
  bind_cols(datos_imputados) %>% 
   mutate(International.plan = ifelse(International.plan == "Yes", 1, 0),
          Voice.mail.plan = ifelse(Voice.mail.plan == "Yes", 1, 0)) %>% 
   select(-c(Account.length, Area.code, Total.intl.calls, Total.intl.charge, International_calls, International_charges, Total.day.charge, Total.eve.charge, Total.night.charge)) %>% 
  mutate_if(is.logical, factor) %>% 
   mutate_if(is.character, factor)
 
 
 
```


* Para poder entender el fenómeno estudiado se estima un modelo logit. 

* Se evidencia que el hecho de tener un plan internacional incrementa la probabilidad de que el cliente abandone la empresa.

* Los clientes que tienen el plan de voicemail presentan mayor probabilidad de permanecer en la empresa que su contraparte (aquellos que no tienen el plan de voicemail).

* A medida de que se incrementa el número de mensajes enviados, se aumenta la probabilidad de que el cliente abandone la empresa.

* A mayor cantidad de minutos consumidos en la mañana, tarde y noche, mayor propensión a abandonar la empresa.

* Los usuarios que registran mayor cantidad de llamadas a los servicios de atención al cliente son los más propensos a convertirse en ex-usuarios.

* Los clientes que realizan llamadas internacionales tienden a permanecer en la empresa.


```{r, echo = FALSE, message = FALSE, warning = FALSE}
 
Logit <- data_churn %>%
         select(-State) %>% 
         glm(Churn ~ .  ,
              family = binomial(link = "logit"), data = .)

stargazer::stargazer(Logit, type='text')
```


### Construcción del modelo

* Para la construcción del modelo churn, se divide la data en el training set y testing set.

* Debido a problemas con la clase desequilibrada en la variable dependiente, se utiliza la técnica de upsampling.

* Para la modelización de los datos se estima un modelo ensamblador ya que presenta la ventaja de   mejorar la precisión, estabilidad del modelo y evitar overfitting. Se utiliza la técnica de bagging para disminuir la varianza de las predicciones. Esta se basa en la combinación de las predicciones de múltiples modelos "débiles" para formar un modelo robusto. Cada uno de los modelos se elabora en base a diferentes remuestreos con remplazo de la población. Para tales fines se modeliza con el random forest, en el cual, se crean múltiples árboles de decisión para formar todo un bosque de árboles. En este se seleccionan de entre todos los predictores una muestra aleatoria de "m" predictores como candidatos para cada modelo. En ese tenor, es una combinación de remuestreo de observaciones y de predictores.

* La métrica a maximizar es el AUC. En ese tenor, se procede a realizar el tuning de los hiperparámetros. 


```{r, echo = FALSE, message = FALSE, warning = FALSE}
# Build a model
set.seed(10)

data_split <- initial_split(data_churn, strata = Churn)

training_data <- training(data_split)

testing_data <- testing(data_split)

```



```{r, echo = FALSE, message = FALSE, warning = FALSE}


rf_recipe <- recipe(Churn ~ ., data = training_data) %>% 
  update_role(State, new_role = "ID") %>% 
  step_dummy(all_nominal(), - all_outcomes(), -has_role("ID")) %>% 
  step_upsample(Churn) %>%  
  step_normalize(all_numeric())
 
rf_prep <- prep(rf_recipe)

rf_juiced <- juice(rf_prep)

```



```{r, echo = FALSE, message = FALSE, warning = FALSE}

tune_spec <- rand_forest(
  mtry = tune(),
  trees = 1000,
  min_n = tune()
) %>%
  set_mode("classification") %>%
  set_engine("ranger")


# Workflow

tune_wf <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(tune_spec)

```



```{r, cache = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Tuning Hyperparameters

set.seed(10)

rf_folds <- vfold_cv(training_data)


doParallel::registerDoParallel()

set.seed(10)
tune_rf <- tune_grid(
  tune_wf,
  resamples = rf_folds,
  grid = 20
)

 
```



```{r, echo = FALSE, message = FALSE, warning = FALSE}
tune_rf %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(x = value, y = mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~ parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC") +
  theme_minimal()
```


```{r, cache = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
rf_grid <- grid_regular(
  mtry(range = c(4, 10)),
  min_n(range = c(35,45)),
  levels = 5
)

set.seed(10)

rf_model_tune <- tune_grid(
  tune_wf,
  resamples = rf_folds,
  grid = rf_grid
)
```
  
```{r, echo = FALSE, message = FALSE, warning = FALSE}
rf_model_tune %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(x = mtry, y = mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "AUC") +
  theme_minimal()
```


```{r,  echo = FALSE, message = FALSE, warning = FALSE}
best_auc <- select_best(rf_model_tune, "roc_auc")

final_rf <- finalize_model(
  tune_spec,
  best_auc
)

 
```

* Se evidencia que las variables con mayor importancia son: 
  + El total de minutos consumidos en el día.
  + Llamadas a los servicios de atención.
  + Poseer un plan internacional.
  + Consumo de minutos en la tarde.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(Churn ~ .,
    data = juice(rf_prep) 
  ) %>%
  vip(geom = "point") +  
  theme_minimal()
```


  
```{r, echo = FALSE, message = FALSE, warning = FALSE}
# Let’s make a final workflow, and then fit one last time, using the convenience function
# last_fit(). This function fits a final model on the entire training set and evaluates on
# the testing set. We just need to give this funtion our original train/test split.

final_wf <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(final_rf)


final_model <- final_wf %>%
  last_fit(data_split)


# final_model %>%
#  collect_metrics()


# The metrics for the test set look good and indicate we did not overfit during tuning.
# Let’s bind our testing results back to the original test set, and make one more map. 
# Where in San Francisco are there more or less incorrectly predicted trees?
  
#   final_model %>%
#   collect_predictions() %>%
#  mutate(correct = case_when(
#    Churn == .pred_class ~ "Correct",
#     TRUE ~ "Incorrect"
#   )) %>%
#   bind_cols(testing_data)  
   
  

# Confussion matrix
final_model %>% 
  collect_predictions() %>% 
  conf_mat(Churn, .pred_class)

 

final_model %>%
  collect_predictions() %>%
  roc_curve(Churn, .pred_TRUE) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(size = 1.5, color = "midnightblue") +
  geom_abline(
    lty = 2, alpha = 0.5,
    color = "gray50",
    size = 1.2
  ) +
  theme_minimal()
 
 
 
resulados <-  final_model %>%
  collect_predictions() %>%
    select(actual = Churn, predicted = .pred_class)  
``` 

### Desempeño del modelo 
 
 
 * Alrededor del 95% de los casos fueron clasificados correctamente usando la base completa, por ende, no se evidencia overfitting. 
 
 
 * En este caso, los falsos negativos son más costosos que los falsos positivos debido a que establecer erróneamente que un cliente se quedará en la empresa hace que este no sea analizado por el departamento de retenciones. En ese tenor, el objetivo es minimizar los falsos negativos, los cuales, representan alrededor del 2% de los casos. 
 
```{r, echo = FALSE,  message = FALSE, warning = FALSE}
plot_confusion_matrix(tidy(confusionMatrix(resulados$actual, resulados$predicted)$table), 
                      targets_col = "Reference", 
                      predictions_col = "Prediction",
                      counts_col = "n")
 
```

### Notas finales
 
* Para continuar mejorando las predicciones del modelo se recomienda:

  + Seguir con el tuning de los hiperparámetros.
  + Estimación de otros modelos.
  + Stacking de modelos.
  
  